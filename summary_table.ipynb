{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aab325-2055-4d33-be33-948441584170",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Geenerate a summary table, agg on time, for all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b486756f-e1b5-463e-b87b-e31685ccbc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id    sales         ly      lgb      yhat  sales_diff_ly  \\\n",
      "0  NOISE20   457584   611664.0   513850  456454.0      -154080.0   \n",
      "1  NOISE21  1001938  1057665.0  1051598  931509.0       -55727.0   \n",
      "2  NOISE22    76716   116942.0    95806  109599.0       -40226.0   \n",
      "3  NOISE23   415338   632826.0   541016  598480.0      -217488.0   \n",
      "4  NOISE24  1115576  1307600.0  1156332  994942.0      -192024.0   \n",
      "\n",
      "   sales_diff_lgb  sales_diff_yhat  \n",
      "0          -56266           1130.0  \n",
      "1          -49660          70429.0  \n",
      "2          -19090         -32883.0  \n",
      "3         -125678        -183142.0  \n",
      "4          -40756         120634.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data_file = \"/home/py/data/PREDICT_SALES_v1/data/processed/merged.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Rename columns to match your requirements\n",
    "df.rename(columns={\n",
    "    'predict_cluster_kmeans_fs_sales': 'kmeans',\n",
    "    'predict_cluster_volume_fs_sales': 'volume',\n",
    "    'predict_cluster_seasonal_fs_sales': 'seasonal',\n",
    "    'predict_cluster_hac_s_sales': 'hac',\n",
    "    'predict_all_sales': 'all'\n",
    "}, inplace=True)\n",
    "\n",
    "# Specify your start week here\n",
    "start_week = 2839  # for example\n",
    "\n",
    "# Filter the DataFrame for rows where epoch_week is greater or equal to start_week\n",
    "filtered_df = df[df['epoch_week'] >= start_week]\n",
    "\n",
    "# Define the columns to sum\n",
    "columns_to_sum = ['sales', 'ly', 'kmeans', 'volume', 'seasonal', 'hac', 'all', 'yhat']\n",
    "\n",
    "# Sum the columns for each item_id\n",
    "sum_df = filtered_df.groupby('item_id')[columns_to_sum].sum().reset_index()\n",
    "\n",
    "# Calculate absolute differences and find closest value\n",
    "model_cols = ['kmeans', 'volume', 'seasonal', 'hac', 'all']\n",
    "columns_to_sum = ['sales', 'ly', 'kmeans', 'volume', 'seasonal', 'hac', 'all', 'yhat', 'lgb']\n",
    "# sum_df['lgb'] = sum_df[model_cols].sub(sum_df['sales'], axis=0).abs().idxmin(axis=1).apply(lambda x: sum_df.loc[sum_df.name, x], axis=1)\n",
    "closest_columns = sum_df[model_cols].sub(sum_df['sales'], axis=0).abs().idxmin(axis=1)\n",
    "\n",
    "# Extract values from closest columns using list comprehension\n",
    "sum_df['lgb'] = [sum_df.loc[idx, col] for idx, col in closest_columns.items()]\n",
    "# Convert the 'lgb' column to integer type\n",
    "sum_df['lgb'] = sum_df['lgb'].astype(int)\n",
    "\n",
    "# Calculate the differences\n",
    "for col in columns_to_sum[1:]:  # skip 'sales' since it's the base for subtraction\n",
    "    sum_df[f'sales_diff_{col}'] = sum_df['sales'] - sum_df[col]\n",
    "\n",
    "# # Rename columns to match your requirements\n",
    "# sum_df.rename(columns={\n",
    "#     'predict_cluster_kmeans_fs_sales': 'sum_kmeans',\n",
    "#     'predict_cluster_volume_fs_sales': 'sum_volume',\n",
    "#     'predict_cluster_seasonal_fs_sales': 'sum_seasonal',\n",
    "#     'predict_cluster_hac_s_sales': 'sum_hac',\n",
    "#     'predict_all_sales': 'sum_all',\n",
    "#     'yhat': 'sum_yhat'\n",
    "# }, inplace=True)\n",
    "# 'item_id', 'sales', 'ly', 'kmeans', 'volume', 'seasonal', 'hac', 'all',\n",
    "#        'yhat', 'sales_diff_ly', 'sales_diff_kmeans', 'sales_diff_volume',\n",
    "#        'sales_diff_season\n",
    "# Select and reorder columns as necessary\n",
    "final_columns = [\n",
    "    'item_id', 'sales', 'ly', 'lgb',\n",
    "    'yhat', 'sales_diff_ly', 'sales_diff_lgb','sales_diff_yhat'\n",
    "]\n",
    "final_df = sum_df[final_columns]\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df.head())\n",
    "data_file = \"/home/py/data/PREDICT_SALES_v1/data/processed/summary_table.csv\"\n",
    "final_df.to_csv(data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdec889-ff73-43e7-8e36-47fcf9252f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'sales', 'ly', 'kmeans', 'volume', 'seasonal', 'hac', 'all',\n",
      "       'yhat', 'lgb', 'sales_diff_ly', 'sales_diff_kmeans',\n",
      "       'sales_diff_volume', 'sales_diff_seasonal', 'sales_diff_hac',\n",
      "       'sales_diff_all', 'sales_diff_yhat', 'sales_diff_lgb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sum_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bdb97-4b6d-474e-a136-e07dc55c77e2",
   "metadata": {},
   "source": [
    "## Generate summary stats/performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770fc982-9dd8-4145-a480-f09e63fa97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  sales                              ly     yhat       lgb\n",
      "                   mean std      min      max  <lambda> <lambda>  <lambda>\n",
      "item_id                                                                   \n",
      "NOISE20        457584.0 NaN   457584   457584  154080.0     0.25   56266.0\n",
      "NOISE21       1001938.0 NaN  1001938  1001938   55727.0     7.03   49660.0\n",
      "NOISE22         76716.0 NaN    76716    76716   40226.0    42.86   19090.0\n",
      "NOISE23        415338.0 NaN   415338   415338  217488.0    44.09  125678.0\n",
      "NOISE24       1115576.0 NaN  1115576  1115576  192024.0    10.81   40756.0\n",
      "...                 ...  ..      ...      ...       ...      ...       ...\n",
      "STYCOL006692    27156.0 NaN    27156    27156   24671.0    91.45  -20130.0\n",
      "STYCOL006693    18927.0 NaN    18927    18927   16241.0    86.62  -10448.0\n",
      "STYCOL006694    13246.0 NaN    13246    13246   10809.0    83.13     411.0\n",
      "STYCOL006695    13108.0 NaN    13108    13108   10797.0    83.99   -3860.0\n",
      "STYCOL006696    23436.0 NaN    23436    23436   12047.0    85.16     154.0\n",
      "\n",
      "[6376 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example data structure (columns: Item, Sales, LY, Prophet, LightGBM, Time)\n",
    "data_file = \"/home/py/data/PREDICT_SALES_v1/data/processed/summary_table.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Summary statistics for each item\n",
    "item_stats = df.groupby(\"item_id\").agg({\n",
    "    \"sales\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "    \"ly\": lambda x: np.sqrt(np.mean((x - df[\"sales\"])**2)),  # RMSE for LY model\n",
    "    \"yhat\": lambda x: np.mean(np.abs((x - df[\"sales\"])/df[\"sales\"]))*100,  # MAPE\n",
    "    \"lgb\": lambda x: np.mean(x - df[\"sales\"])  # Mean Bias\n",
    "}).round(2)\n",
    "\n",
    "print(item_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa851026-7f4e-4df8-aa73-fa3a2cb294d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1 env",
   "language": "python",
   "name": "ml1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
